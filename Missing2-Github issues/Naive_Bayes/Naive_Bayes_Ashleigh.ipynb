{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashleighdiamond/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from naive_bayes import NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.naive_bayes import NaiveBayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4601, 57), (4601,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('data/spam.csv', delimiter=',')\n",
    "\n",
    "y = data[:, -1]\n",
    "X = data[:, 0:-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=pd.DataFrame(data)\n",
    "L=data[:1, 0:-10]\n",
    "V=pd.DataFrame(L)\n",
    "summ=0\n",
    "L\n",
    "for each in L:\n",
    "    #print(each)\n",
    "    for x in each:\n",
    "        pass\n",
    "    \n",
    "        #print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayes(object):\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        '''\n",
    "        INPUT:\n",
    "        - alpha: float, laplace smoothing constant\n",
    "        '''\n",
    "\n",
    "        self.class_totals = None\n",
    "        self.class_feature_totals = None\n",
    "        self.class_counts = None\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def _compute_likelihood(self, X, y):\n",
    "        '''\n",
    "        INPUT:\n",
    "        - X: 2d numpy array, feature matrix\n",
    "        - y: numpy array, labels\n",
    "        Compute the totals for each class and the totals for each feature\n",
    "        and class.\n",
    "        '''\n",
    "        self.class_totals = Counter()\n",
    "        self.class_feature_totals = defaultdict(Counter)\n",
    "        \n",
    "        #this sums up all of the rows per feature for each class\n",
    "        for row_num, row in enumerate(X):\n",
    "            for col_num, value in enumerate(row):\n",
    "                #if self.class_feature_totals[y[row_num]][col_num] == 0:\n",
    "                 #   self.class_feature_totals[y[row_num]][col_num] = self.alpha\n",
    "                #this adds the value to the \n",
    "                self.class_feature_totals[y[row_num]][col_num] += value\n",
    "        \n",
    "        #this sums all of the features each of the 2 classes\n",
    "        self.len_class0=0\n",
    "        self.total_class1=0\n",
    "        bottom=0\n",
    "        for clss, t in self.class_feature_totals.items():\n",
    "            #n features\n",
    "            for alll,p in t.items():\n",
    "                #I decided to divide alpha by 100 because the data that we are working with is a rate\n",
    "                self.class_feature_totals[clss][alll]+=self.alpha\n",
    "                # or is it\n",
    "                #self.class_feature_totals[clss][alll]+=self.alpha/100\n",
    "                self.class_totals[clss]+=p\n",
    "                \n",
    "        #print(self.class_feature_totals)\n",
    "        #print(self.class_totals)\n",
    "                   \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        INPUT:\n",
    "        - X: 2d numpy array, feature matrix\n",
    "        - y: numpy array, labels\n",
    "        OUTPUT: None\n",
    "        '''\n",
    "\n",
    "        # This section is given to you.\n",
    "        \n",
    "        # compute priors\n",
    "        self.class_counts = Counter(y)\n",
    "\n",
    "        # compute likelihoods\n",
    "        self._compute_likelihood(X, y)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        INPUT:\n",
    "        - X: 2d numpy array, feature matrix\n",
    "        OUTPUT:\n",
    "        - predictions: numpy array\n",
    "        Implement the predict method. For each row in the feature matrix X\n",
    "        and for each potential label, you will need to \n",
    "        calculate the log likelihood. You should follow \n",
    "        the formula from above.'''\n",
    "\n",
    "        #predictions = np.zeros(X.shape[0])\n",
    "        \n",
    "        total_docs=0\n",
    "        for _, val in self.class_counts.items():\n",
    "            total_docs+=val\n",
    "        self.class_counts\n",
    "            \n",
    "        print(self.class_counts)\n",
    "        #this is the prob of y in log\n",
    "        counts={}\n",
    "        for each,i in self.class_counts.items():\n",
    "            counts[each]=np.log(self.class_counts[each]/total_docs)\n",
    "        \n",
    "        #i is the class each is a dict containing the feature\n",
    "        likelihood={}\n",
    "        sums=0\n",
    "        for i,each in self.class_feature_totals.items():\n",
    "            for l, feature_count in each.items():\n",
    "                if i in likelihood.keys():\n",
    "                    likelihood[i][l]=feature_count/self.class_totals[i]\n",
    "                else:\n",
    "                    likelihood[i] = {}\n",
    "                    likelihood[i][l]=feature_count/self.class_totals[i]\n",
    "        pred={}\n",
    "        for classes,feature_num in likelihood.items():\n",
    "            pred[classes]=[]\n",
    "            for row in X:\n",
    "                #key is feature num and value is the value\n",
    "                sums=0\n",
    "                for key, value in feature_num.items():\n",
    "                    sums+=row[key]*np.log(likelihood[classes][key])\n",
    "                pred[classes].append(sums)\n",
    "                \n",
    "        #print(pred[0])\n",
    "        y_pred=[]\n",
    "        for i in range(len(pred[0])):\n",
    "            if pred[0][i]>pred[1][i]:\n",
    "                y_pred.append(0)\n",
    "            else:\n",
    "                y_pred.append(1)\n",
    "        #print(y_pred)\n",
    "        return y_pred\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    def score(self, predict, true_y):\n",
    "        print(type(predict))\n",
    "            \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        INPUT:\n",
    "        - X: 2d numpy array, feature matrix\n",
    "        - y: numpy array, labels\n",
    "        OUTPUT:\n",
    "        - accuracy: float between 0 and 1\n",
    "        Calculate the accuracy, the percent of documents predicted correctly.\n",
    "        '''\n",
    "\n",
    "        return sum(self.predict(X) == y) / float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(predict, true_y):\n",
    "    predict=np.asarray(predict)\n",
    "    X=abs(predict)-abs(true_y)\n",
    "    i=0\n",
    "    print(X)\n",
    "    for each in X:\n",
    "        if each==0:\n",
    "            i+=1\n",
    "    print(i)\n",
    "    print(len(X))\n",
    "    print(i/len(X))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 2257, 1.0: 1423})\n",
      "[ 1.  0.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0. -1. -1.  0.  0. -1.\n",
      "  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.\n",
      " -1.  0.  1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1. -1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1. -1. -1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0. -1.  0.  0. -1.  0.  0.  0.  0. -1.  0.  0. -1.  0.  1.  0.\n",
      "  0.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0. -1. -1.  0.  0.  0.  0.\n",
      "  0. -1.  1.  1. -1.  0.  0. -1. -1. -1.  0. -1. -1.  0. -1.  0.  0.  0.\n",
      " -1.  0.  0.  1.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1. -1.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0.\n",
      " -1.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0. -1.  0.  0.  0. -1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.\n",
      " -1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1. -1. -1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0. -1.  0.  0.  0.  1. -1.  0.  0. -1.  0. -1. -1.  0.  1.  1.  0.  1.\n",
      "  0. -1.  0. -1.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0. -1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      " -1.  0.  0.  0. -1.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0. -1.  0.  0.  0.  0.  0.  1.  0.  0.  0. -1. -1.  0.  0.  0. -1.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0. -1.  0.  0.  0.  0.\n",
      "  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      " -1.  0.  1.  0.  0.  0.  0.  1. -1.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.\n",
      "  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  1.  1.  0.  0. -1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.\n",
      "  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  1.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0. -1.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0. -1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0. -1. -1.  0. -1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0. -1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0. -1.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0. -1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  1.  0.  1.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0. -1.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.\n",
      "  0.  0.  0. -1.  0. -1. -1.  0.  0.  0.  0. -1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0. -1. -1.  1. -1.  0.  0. -1.  1.  0.  0.  0.\n",
      "  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0. -1.  0.  1.\n",
      "  0.  0.  0.  0.  1. -1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0. -1.  0.  0.  1.\n",
      "  0.  0.  0.]\n",
      "730\n",
      "921\n",
      "0.7926167209554832\n"
     ]
    }
   ],
   "source": [
    "naive=NaiveBayes()\n",
    "naive._compute_likelihood(X_train,y_train)\n",
    "naive.fit(X_train,y_train)\n",
    "predict=naive.predict(X_test)\n",
    "#naive.score(predict,y_test)\n",
    "#naive.score(predict, y_test)\n",
    "score(predict, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
